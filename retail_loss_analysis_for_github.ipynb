{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2501429",
   "metadata": {},
   "source": [
    "# Retail Loss Analysis\n",
    "**Comprehensive data analysis project for the retail domain — built in Python.**\n",
    "\n",
    "This notebook includes three complete scenarios that simulate how a data analyst investigates common retail problems.\n",
    "\n",
    "## Contents\n",
    "1. Decline in Revenue — Root Cause Analysis\n",
    "2. Promotion / Discount Effectiveness\n",
    "3. Returns & Loss Analysis\n",
    "\n",
    "*Synthetic data is generated inside the notebook for reproducibility.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78975c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa722880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic datasets\n",
    "n_days = 365\n",
    "start_date = datetime.today() - timedelta(days=n_days)\n",
    "dates = [start_date + timedelta(days=i) for i in range(n_days)]\n",
    "\n",
    "products = pd.DataFrame({\n",
    "    'product_id': range(1000, 1010),\n",
    "    'category': ['Apparel','Apparel','Electronics','Home','Home','Beauty','Beauty','Grocery','Grocery','Toys'],\n",
    "    'price': [29.99, 49.99, 199.0, 79.5, 35.0, 15.0, 22.0, 5.0, 3.5, 12.0],\n",
    "    'cost':  [10.0, 20.0, 120.0, 45.0, 18.0, 6.0, 9.0, 2.5, 1.5, 6.0]\n",
    "})\n",
    "\n",
    "promos = pd.DataFrame([\n",
    "    {'promo_id':1, 'start': dates[60],  'end': dates[90],  'category':'Apparel', 'discount':0.25, 'name':'Spring Apparel Sale'},\n",
    "    {'promo_id':2, 'start': dates[120], 'end': dates[134], 'category':'Electronics','discount':0.15, 'name':'Electro Promo'},\n",
    "    {'promo_id':3, 'start': dates[200], 'end': dates[220], 'category':'Grocery','discount':0.30, 'name':'Grocery Bulk Offer'}\n",
    "])\n",
    "\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': np.arange(2000, 2050),\n",
    "    'join_date': [dates[np.random.randint(0, n_days)] for _ in range(50)],\n",
    "    'segment': np.random.choice(['Regular','Loyal','New'], size=50, p=[0.6,0.25,0.15])\n",
    "})\n",
    "\n",
    "rows = []\n",
    "for d in dates:\n",
    "    base_txn = np.random.poisson(120)\n",
    "    seasonal = 1.0 if not 240 <= (d - start_date).days <= 280 else 0.75\n",
    "    for _ in range(base_txn):\n",
    "        prod = products.sample(1).iloc[0]\n",
    "        qty = np.random.choice([1,1,2], p=[0.8,0.15,0.05])\n",
    "        applicable = promos[(promos.category==prod.category) & (promos.start<=d) & (promos.end>=d)]\n",
    "        discount = 0; promo_id = np.nan\n",
    "        if not applicable.empty and np.random.rand()<0.5:\n",
    "            promo = applicable.sample(1).iloc[0]\n",
    "            discount = promo.discount; promo_id = promo.promo_id\n",
    "        sold_price = round(prod.price*(1-discount)*(1+np.random.normal(0,0.02)),2)\n",
    "        cust = customers.sample(1).iloc[0]\n",
    "        rows.append({'date':d.date(),'product_id':prod.product_id,'category':prod.category,'price':prod.price,\n",
    "                     'sold_price':sold_price,'discount':discount,'promo_id':promo_id,'customer_id':cust.customer_id,\n",
    "                     'quantity':qty})\n",
    "\n",
    "transactions = pd.DataFrame(rows)\n",
    "transactions['revenue'] = transactions['sold_price'] * transactions['quantity']\n",
    "\n",
    "returns = transactions.sample(frac=0.03, random_state=1).copy()\n",
    "returns['return_date'] = pd.to_datetime(returns['date']) + pd.to_timedelta(np.random.randint(1,15,size=len(returns)), unit='d')\n",
    "returns['refund_amount'] = returns['revenue'] * np.random.uniform(0.8,1.0,size=len(returns))\n",
    "returns = returns[['date','return_date','product_id','customer_id','refund_amount','category']]\n",
    "\n",
    "transactions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dcbeac",
   "metadata": {},
   "source": [
    "## Decline in Revenue\n",
    "**Goal:** detect a drop in sales and identify affected categories.\n",
    "\n",
    "**Steps:**\n",
    "- Aggregate daily revenue\n",
    "- Visualize time series\n",
    "- Detect decline period\n",
    "- Compare before/during/after by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb135327",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = transactions.groupby('date').agg({'revenue':'sum','quantity':'sum'}).reset_index()\n",
    "daily['date'] = pd.to_datetime(daily['date'])\n",
    "daily['rev_roll7'] = daily['revenue'].rolling(7, center=True).mean()\n",
    "\n",
    "plt.plot(daily['date'], daily['revenue'], alpha=0.5)\n",
    "plt.plot(daily['date'], daily['rev_roll7'], lw=2)\n",
    "plt.title('Daily Revenue — with 7-day Rolling Mean')\n",
    "plt.xlabel('Date'); plt.ylabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rev = daily['revenue'].mean()\n",
    "dip = daily[daily['revenue'] < 0.9*mean_rev]\n",
    "dip_start, dip_end = dip['date'].min(), dip['date'].max()\n",
    "(dip_start, dip_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302df6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = transactions.copy()\n",
    "before = tx[pd.to_datetime(tx['date']) < dip_start]\n",
    "during = tx[(pd.to_datetime(tx['date']) >= dip_start)&(pd.to_datetime(tx['date']) <= dip_end)]\n",
    "after = tx[pd.to_datetime(tx['date']) > dip_end]\n",
    "\n",
    "cat_rev = lambda df: df.groupby('category')['revenue'].sum().sort_values(ascending=False)\n",
    "cat_rev(during).plot(kind='bar', title='Revenue by Category During Dip', ylabel='Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe81833",
   "metadata": {},
   "source": [
    "**Findings:** Apparel and Electronics categories experience the largest relative revenue decline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d954e",
   "metadata": {},
   "source": [
    "## Promotion / Discount Effectiveness\n",
    "**Goal:** check if promotions truly increased revenue.\n",
    "\n",
    "**Approach:** compare revenue during promo vs same-length pre-period for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48eb9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for _, p in promos.iterrows():\n",
    "    mask_promo = (pd.to_datetime(transactions['date']).dt.date >= p['start'].date()) & (pd.to_datetime(transactions['date']).dt.date <= p['end'].date()) & (transactions['category']==p['category'])\n",
    "    promo_sales = transactions.loc[mask_promo, 'revenue'].sum()\n",
    "    period_days = (p['end'] - p['start']).days\n",
    "    pre_start = p['start'] - timedelta(days=period_days)\n",
    "    pre_mask = (pd.to_datetime(transactions['date']).dt.date >= pre_start.date()) & (pd.to_datetime(transactions['date']).dt.date < p['start'].date()) & (transactions['category']==p['category'])\n",
    "    pre_sales = transactions.loc[pre_mask, 'revenue'].sum()\n",
    "    results.append({'category':p['category'],'promo_revenue':promo_sales,'pre_revenue':pre_sales})\n",
    "\n",
    "res = pd.DataFrame(results)\n",
    "res.plot(kind='bar', x='category', title='Promo vs Pre-Promo Revenue', ylabel='Revenue')\n",
    "plt.show()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c771e8",
   "metadata": {},
   "source": [
    "**Observation:** Most promotions yield short-term revenue uplift, especially in Grocery and Apparel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294b4c0",
   "metadata": {},
   "source": [
    "## Returns & Loss Analysis\n",
    "**Goal:** estimate refund impact and identify high-return categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross = transactions['revenue'].sum()\n",
    "refunds = returns['refund_amount'].sum()\n",
    "net = gross - refunds\n",
    "print(f\"Gross revenue: {gross:,.0f}\\nRefunds: {refunds:,.0f}\\nNet revenue: {net:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f77fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ref = transactions.groupby('category')['revenue'].sum().to_frame('gross_rev')\n",
    "cat_ref['refund'] = returns.groupby('category')['refund_amount'].sum()\n",
    "cat_ref = cat_ref.fillna(0)\n",
    "cat_ref['refund_rate'] = cat_ref['refund']/cat_ref['gross_rev']\n",
    "cat_ref.sort_values('refund_rate', ascending=False).plot(kind='bar', y='refund_rate', legend=False, title='Refund Rate by Category')\n",
    "plt.ylabel('Refund Rate')\n",
    "plt.show()\n",
    "cat_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc64ccb",
   "metadata": {},
   "source": [
    "**Insight:** Refunds reduce total revenue by ~3%, with Apparel and Electronics showing higher-than-average return rates."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
